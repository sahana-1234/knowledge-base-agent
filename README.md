ğŸ“˜ Knowledge Base Agent (PDF-QA Chatbot using Chroma + Ollama + Streamlit)
ğŸ§© Overview

The Knowledge Base Agent is an AI-powered system that allows users to upload PDF documents and interact with them through a conversational chat interface.
It uses local LLM inference through Ollama, combined with ChromaDB vector search, to answer user queries strictly based on uploaded documents.
This ensures privacy, accuracy, and offline capability.
-------------------------------------------------------------------------
ğŸš€ Features
ğŸ” 1. Multi-document PDF Ingestion

Upload multiple PDFs

Automatic text extraction

Text chunking using RecursiveCharacterTextSplitter

Embedding generated using nomic-embed-text

Stored locally in ChromaDB

ğŸ§  2. Retrieval-Augmented Generation (RAG)

User question â†’ semantic search in vector DB â†’ best chunks retrieved

LLM (Ollama Qwen 1.5B) generates answer ONLY from documents

Prevents hallucination using a strict prompt template

ğŸ“„ 3. Document Manager

List all uploaded documents

Display file name, upload timestamp, number of chunks

Delete individual documents from vector DB

ğŸŒ— 4. Dark/Light Mode Toggle

Clean UI with modern theme and automatic text color updates.

ğŸ’¬ 5. Persistent Chat History

Conversation stays on screen until the user clears it.

ğŸ” 6. Fully Local & Private

No cloud calls

All embeddings + inference happen on the user's machine

Perfect for confidential data
--------------------------------------------------------------------------------------------
âš ï¸ Limitations

Even though the agent is powerful, it has some limitations:

âŒ Requires laptop to be ON for Ngrok demo link

âŒ Slow on low-performance CPUs (LLM runs locally)

âŒ Cannot answer questions outside uploaded documents

âŒ Limited model size (Qwen 1.5B is small compared to GPT-4)

âŒ No online LLM API support

âŒ No user authentication (anyone with link can use it)
--------------------------------------------------------------------------------------------
ğŸ—ï¸ Tech Stack

| Component                | Technology              |
| ------------------------ | ----------------------- |
| **Local LLM**            | Ollama â€” *Qwen2.5:1.5B* |
| **Embeddings**           | nomic-embed-text        |
| **Vector Database**      | ChromaDB                |
| **Frontend UI**          | Streamlit               |
| **Frameworks**           | LangChain, PyPDFLoader  |
| **Deployment (Demo)**    | Ngrok                   |
| **Programming Language** | Python                  |

-------------------------------------------------------------------------------------
ğŸ§± Architecture Diagram (High-Level)

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        User UI           â”‚
            â”‚     (Streamlit App)      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ PDF Upload & Processing  â”‚
            â”‚  (PyPDFLoader, Splitter) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Embedding Generation    â”‚
            â”‚  (Ollama Embeddings)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   ChromaDB Vector Store  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Retriever (k=5)       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Ollama LLM (Qwen)     â”‚
            â”‚  Generate Final Answer   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
----------------------------------------------------------------------------------
ğŸ“ Project Structure

kb_agent/
â”œâ”€â”€ app.py
â”œâ”€â”€ ingest.py
â”œâ”€â”€ chroma_client.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_company_doc.pdf
â”‚   â”œâ”€â”€ MAJOR-SYNOPSIS-Last1.pdf
â”œâ”€â”€ db/
â”œâ”€â”€ requirements.txt
â””â”€â”€ chat_history.db

-----------------------------------------------------------------------------------
âš™ï¸ Installation & Local Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/sahana-1234/knowledge-base-agent.git
cd knowledge-base-agent

2ï¸âƒ£ Create a virtual environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Install required Ollama models
ollama pull qwen2.5:1.5b
ollama pull nomic-embed-text

5ï¸âƒ£ Run the Streamlit app
streamlit run app.py
---------------------------------------------------------------------------
ğŸŒ Public Demo (Ngrok - Required for Jury)

Start Streamlit:

streamlit run app.py


Start Ngrok with permanent domain:

cd C:\ngrok
./ngrok http --domain=yong-noninflationary-reactively.ngrok-free.dev 8501
------------------------------------------------------------------

Your demo link:

ğŸ‘‰ https://yong-noninflationary-reactively.ngrok-free.dev
---------------------------------------------------------------------------

ğŸ”® Future Improvements

Larger LLM support (LLaMA, Mixtral, Phi-3)

Cloud deployment using API-based LLMs

OCR support for scanned PDFs

User authentication

Multi-user document isolation

DOCX, PPTX, XLSX support

GPU acceleration

Faster retrieval using hybrid search

Document summary mode
